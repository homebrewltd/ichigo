{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whisperspeech.pipeline import Pipeline\n",
    "\n",
    "class TTSProcessor:\n",
    "    def __init__(self, num_processes_per_gpu, num_gpus):\n",
    "        \"\"\"TTS Processor to generate TTS from prompts.\"\"\"\n",
    "        self.num_processes_per_gpu = num_processes_per_gpu\n",
    "        self.num_gpus = num_gpus\n",
    "\n",
    "    def distribute_pipe(self):\n",
    "        \"\"\"Distribute the pipeline.\"\"\"\n",
    "        self.pipes = []\n",
    "        for gpu_id in range(self.num_gpus):\n",
    "            for pipe_id in range(self.num_processes_per_gpu):\n",
    "                self.pipes.append(Pipeline(s2a_ref=\"collabora/whisperspeech:s2a-q4-tiny-en+pl.model\", ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# random float32 tensor with normal distribution\n",
    "x = torch.randn(10, 2, dtype=torch.float32).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow.Tensor>\n",
       "type: float\n",
       "shape: (10, 2)\n",
       "strides: (8, 4)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyarrow as pa\n",
    "\n",
    "# convert to pyarrow tensor\n",
    "x_pa = pa.Tensor.from_numpy(x)\n",
    "x_pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow.Tensor>\n",
       "type: float\n",
       "shape: (10, 2)\n",
       "strides: (8, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = pa.schema([pa.field(\"feature\", pa.list_(pa.float32())), pa.field(\"label\", pa.list_(pa.float32()))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "\n",
    "\n",
    "tensor, sr = torchaudio.load(\"/home/root/Workspace/synthetic_data_generation/sound_instruct_llama3/data/new_audio/audio_2499.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00079372, -0.00075542, -0.00076741, ...,  0.00136764,\n",
       "       -0.00015275, -0.00142147], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.squeeze(0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import torchaudio\n",
    "\n",
    "# Define the schema\n",
    "schema = pa.schema([\n",
    "    pa.field(\"feature\", pa.list_(pa.float32())),\n",
    "    pa.field(\"label\", pa.list_(pa.float32()))\n",
    "])\n",
    "\n",
    "# Load the audio file\n",
    "tensor, sr = torchaudio.load(\"/home/root/Workspace/synthetic_data_generation/sound_instruct_llama3/data/new_audio/audio_2499.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded audio file with sample rate: 24000\n",
      "Opened data.arrow for writing.\n",
      "Prepared pyarrow arrays for feature and label.\n",
      "Created RecordBatch with schema: feature: list<item: float>\n",
      "  child 0, item: float\n",
      "label: list<item: float>\n",
      "  child 0, item: float\n",
      "Wrote RecordBatch to data.arrow.\n",
      "Closed the writer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2736918/2364974236.py:25: FutureWarning: Schema passed to names= option, please pass schema= explicitly. Will raise exception in future\n",
      "  batch = pa.RecordBatch.from_arrays([feature_array, label_array], schema)\n"
     ]
    }
   ],
   "source": [
    "import pyarrow as pa\n",
    "import torchaudio\n",
    "\n",
    "# Define the schema\n",
    "schema = pa.schema([\n",
    "    pa.field(\"feature\", pa.list_(pa.float32())),\n",
    "    pa.field(\"label\", pa.list_(pa.float32()))\n",
    "])\n",
    "\n",
    "# Load an audio file\n",
    "tensor, sr = torchaudio.load(\"/home/root/Workspace/synthetic_data_generation/sound_instruct_llama3/data/new_audio/audio_2499.wav\")\n",
    "print(f\"Loaded audio file with sample rate: {sr}\")\n",
    "\n",
    "# Open the file sink for writing\n",
    "with pa.OSFile(\"data.arrow\", \"wb\") as sink:\n",
    "    writer = pa.ipc.RecordBatchFileWriter(sink, schema)\n",
    "    print(\"Opened data.arrow for writing.\")\n",
    "\n",
    "    # Prepare the data as pyarrow arrays\n",
    "    feature_array = pa.array([tensor.squeeze(0).numpy()], type=pa.list_(pa.float32()))\n",
    "    label_array = pa.array([tensor.squeeze(0).numpy()], type=pa.list_(pa.float32()))\n",
    "    print(\"Prepared pyarrow arrays for feature and label.\")\n",
    "\n",
    "    # Create a RecordBatch from the arrays\n",
    "    batch = pa.RecordBatch.from_arrays([feature_array, label_array], schema)\n",
    "    print(\"Created RecordBatch with schema:\", schema)\n",
    "\n",
    "    # Write the batch to the file\n",
    "    writer.write_batch(batch)\n",
    "    print(\"Wrote RecordBatch to data.arrow.\")\n",
    "\n",
    "    # Close the writer explicitly\n",
    "    writer.close()\n",
    "    print(\"Closed the writer.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File is corrupted, need to try recovery\n"
     ]
    }
   ],
   "source": [
    "import pyarrow as pa\n",
    "\n",
    "try:\n",
    "    with pa.ipc.open_file('/home/root/Workspace/synthetic_data_generation/sound_instruct_llama3/data/new_tokens_v4.arrow') as reader:\n",
    "        table = reader.read_all()\n",
    "    print(\"File opened successfully\")\n",
    "except pa.lib.ArrowInvalid:\n",
    "    print(\"File is corrupted, need to try recovery\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovery failed: Invalid flatbuffers message.\n"
     ]
    }
   ],
   "source": [
    "import pyarrow as pa\n",
    "\n",
    "try:\n",
    "    with open('/home/root/Workspace/synthetic_data_generation/sound_instruct_llama3/data/new_tokens_v4.arrow', 'rb') as file:\n",
    "        reader = pa.ipc.open_stream(file)\n",
    "        batches = list(reader)\n",
    "        if batches:\n",
    "            table = pa.Table.from_batches(batches)\n",
    "            print(f\"Recovered {len(batches)} record batches\")\n",
    "        else:\n",
    "            print(\"No valid record batches found\")\n",
    "except Exception as e:\n",
    "    print(f\"Recovery failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading file: Not an Arrow file\n"
     ]
    }
   ],
   "source": [
    "import pyarrow as pa\n",
    "\n",
    "def safe_read_arrow(file_path):\n",
    "    try:\n",
    "        with pa.memory_map(file_path, 'r') as source:\n",
    "            reader = pa.ipc.open_file(source)\n",
    "            return [batch for batch in reader]\n",
    "    except pa.ArrowInvalid as e:\n",
    "        print(f\"Error reading file: {e}\")\n",
    "        return None\n",
    "\n",
    "recovered_data = safe_read_arrow('/home/root/Workspace/synthetic_data_generation/sound_instruct_llama3/data/new_tokens_v4.arrow')\n",
    "if recovered_data:\n",
    "    print(f\"Successfully recovered {sum(len(batch) for batch in recovered_data)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at offset 0: Invalid flatbuffers message.\n",
      "Error at offset 1024: Invalid flatbuffers message.\n",
      "Error at offset 2048: Invalid IPC stream: negative continuation token\n",
      "No valid data found in the file.\n",
      "Failed to recover data from the Arrow file.\n"
     ]
    }
   ],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.ipc as ipc\n",
    "\n",
    "def read_partial_arrow_data(file_path, chunk_size=1024):\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            offset = 0\n",
    "            batches = []\n",
    "            while True:\n",
    "                f.seek(offset)\n",
    "                try:\n",
    "                    reader = ipc.open_stream(f)\n",
    "                    while True:\n",
    "                        try:\n",
    "                            batch = reader.read_next_batch()\n",
    "                            batches.append(batch)\n",
    "                        except StopIteration:\n",
    "                            break\n",
    "                except Exception as e:\n",
    "                    print(f\"Error at offset {offset}: {e}\")\n",
    "                offset += chunk_size\n",
    "                if offset >= f.tell():\n",
    "                    break\n",
    "            if batches:\n",
    "                table = pa.Table.from_batches(batches)\n",
    "                return table\n",
    "            else:\n",
    "                print(\"No valid data found in the file.\")\n",
    "                return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Replace 'your_file.arrow' with the path to your IPC file\n",
    "table = read_partial_arrow_data('/home/root/Workspace/synthetic_data_generation/sound_instruct_llama3/data/new_tokens_v4.arrow')\n",
    "if table:\n",
    "    print(table)\n",
    "else:\n",
    "    print(\"Failed to recover data from the Arrow file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.csv as csv\n",
    "\n",
    "class CSVWriter:\n",
    "    def __init__(self, file_path, schema):\n",
    "        self.file_path = file_path\n",
    "        self.schema = schema\n",
    "        self.writer = None\n",
    "        self.open()\n",
    "\n",
    "    def open(self):\n",
    "        self.writer = csv.CSVWriter(self.file_path, self.schema)\n",
    "\n",
    "    def write(self, batch):\n",
    "        self.writer.write(batch)\n",
    "\n",
    "    def close(self):\n",
    "        if self.writer:\n",
    "            self.writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CSV writer for this process\n",
    "schema = pa.schema(\n",
    "    [\n",
    "        pa.field(\"index\", pa.int64()),\n",
    "        pa.field(\"audio\", pa.string()),\n",
    "        pa.field(\"tokens\", pa.string()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "writer = CSVWriter(\"data.csv\", schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def create_random_array_string(size=15):\n",
    "    # random float32 array\n",
    "    array = np.random.rand(size).astype(np.float32)\n",
    "    return json.dumps(array.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random array\n",
    "import numpy as np\n",
    "\n",
    "batch = [\n",
    "    pa.array([1, 2, 3, 4, 5], type=pa.int64()),\n",
    "    pa.array([create_random_array_string() for _ in range(5)], type=pa.string()),\n",
    "    pa.array([create_random_array_string() for _ in range(5)], type=pa.string())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pyarrow.lib.Int64Array object at 0x7ffaadc932e0>\n",
       " [\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5\n",
       " ],\n",
       " <pyarrow.lib.StringArray object at 0x7ffaa790f9a0>\n",
       " [\n",
       "   \"[0.4400988221168518, 0.5239095687866211, 0.723219096660614, 0.2820580303668976, 0.7444203495979309, 0.017944473773241043, 0.3287590742111206, 0.8090250492095947, 0.10484332591295242, 0.3647204041481018, 0.7928389310836792, 0.9845169186592102, 0.12505963444709778, 0.14084535837173462, 0.2445572465658188]\",\n",
       "   \"[0.1545468121767044, 0.138200044631958, 0.6591715216636658, 0.4447644352912903, 0.3121277987957001, 0.5649989247322083, 0.46367937326431274, 0.5253438353538513, 0.18653614819049835, 0.6859237551689148, 0.2547590136528015, 0.6078174114227295, 0.058871880173683167, 0.5905410051345825, 0.8234201669692993]\",\n",
       "   \"[0.4271077811717987, 0.8178958892822266, 0.8086280226707458, 0.02417149767279625, 0.9339762330055237, 0.10169157385826111, 0.24186016619205475, 0.21639375388622284, 0.38006070256233215, 0.3688339591026306, 0.472318559885025, 0.1369962841272354, 0.8693585991859436, 0.31092706322669983, 0.8051314949989319]\",\n",
       "   \"[0.05268659442663193, 0.6216984987258911, 0.965587317943573, 0.3768434226512909, 0.01833374612033367, 0.07730375975370407, 0.02844356559216976, 0.05802208185195923, 0.35453668236732483, 0.7256302237510681, 0.33570730686187744, 0.7922215461730957, 0.5553579330444336, 0.3704172372817993, 0.5258473753929138]\",\n",
       "   \"[0.5381158590316772, 0.6477842330932617, 0.05172381550073624, 0.9615135788917542, 0.6508479118347168, 0.37896978855133057, 0.3031335771083832, 0.6319270730018616, 0.8570177555084229, 0.4436652958393097, 0.7428196668624878, 0.49872028827667236, 0.3176862597465515, 0.06987468898296356, 0.5115572810173035]\"\n",
       " ],\n",
       " <pyarrow.lib.StringArray object at 0x7ffaa790fa60>\n",
       " [\n",
       "   \"[0.02097843959927559, 0.9685634970664978, 0.10974553972482681, 0.4420020282268524, 0.5368331670761108, 0.6487146019935608, 0.8940770030021667, 0.7792506217956543, 0.7708090543746948, 0.6448609828948975, 0.33977770805358887, 0.7582055926322937, 0.8657787442207336, 0.31435707211494446, 0.9031307697296143]\",\n",
       "   \"[0.13948088884353638, 0.9198850989341736, 0.36602267622947693, 0.726215124130249, 0.07974163442850113, 0.5718719959259033, 0.7625268697738647, 0.18673062324523926, 0.12203984707593918, 0.1191054955124855, 0.037911441177129745, 0.46808138489723206, 0.2988021969795227, 0.7027259469032288, 0.352286159992218]\",\n",
       "   \"[0.2708246111869812, 0.8348052501678467, 0.8646947741508484, 0.9329516887664795, 0.15028159320354462, 0.5111807584762573, 0.20644816756248474, 0.5997654795646667, 0.14921589195728302, 0.1373136341571808, 0.34131646156311035, 0.9102164506912231, 0.8433840870857239, 0.9718611836433411, 0.4838202893733978]\",\n",
       "   \"[0.4109937846660614, 0.390249103307724, 0.3931587338447571, 0.8629106283187866, 0.8823914527893066, 0.7031650543212891, 0.0109969861805439, 0.8466512560844421, 0.43117183446884155, 0.847313642501831, 0.4457615911960602, 0.7956170439720154, 0.5707494616508484, 0.48441028594970703, 0.9341138601303101]\",\n",
       "   \"[0.7760711312294006, 0.41437238454818726, 0.39052292704582214, 0.8370614647865295, 0.029565637931227684, 0.10010512173175812, 0.02285141684114933, 0.17060823738574982, 0.5627948045730591, 0.7544226050376892, 0.5555309653282166, 0.9028446674346924, 0.03849741816520691, 0.9485925436019897, 0.34244221448898315]\"\n",
       " ]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_table = pa.table.from_arrays(\n",
    "        batch, schema=csv_writer.schema\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
